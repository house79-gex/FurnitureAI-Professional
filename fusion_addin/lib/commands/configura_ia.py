"""
Comando FAI_ConfiguraIA - Configurazione IA Completa
Versione: 3.0 - Tab chiare + Icone + First Run Detection
"""

import adsk.core
import adsk.fusion
import traceback
import os
import sys

class ConfiguraIACommand:
    """Handler comando FAI_ConfiguraIA"""
    
    def __init__(self):
        self.app = adsk.core.Application.get()
        self.ui = self.app.userInterface
        
        # Setup path
        addon_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        lib_path = os.path.join(addon_path, 'fusion_addin', 'lib')
        if lib_path not in sys.path:
            sys.path.insert(0, lib_path)
        
        from config_manager import ConfigManager
        self.config_manager = ConfigManager(addon_path)
        self.config = self.config_manager.get_ai_config()
        
    def execute(self):
        """Esegui comando"""
        try:
            self.app.log("üöÄ ConfiguraIA: execute() chiamato")
            self.app.log(f"üìä First run: {self.config_manager.is_first_run()}")
            
            # Crea command definition
            cmd_def = self.ui.commandDefinitions.itemById('FAI_ConfiguraIA_Dialog')
            if not cmd_def:
                cmd_def = self.ui.commandDefinitions.addButtonDefinition(
                    'FAI_ConfiguraIA_Dialog',
                    'Configura IA',
                    'Configurazione provider intelligenza artificiale'
                )
                self.app.log("‚úì Command definition creato")
            else:
                self.app.log("‚úì Command definition esistente trovato")
            
            # Handler
            on_command_created = ConfiguraIACommandCreatedHandler(self.config_manager, self.config)
            cmd_def.commandCreated.add(on_command_created)
            
            # Esegui
            self.app.log("üéØ Esecuzione dialog...")
            cmd_def.execute()
            self.app.log("‚úì Dialog eseguito")
            
        except Exception as e:
            self.app.log(f"‚ùå Errore comando Configura IA: {e}")
            self.ui.messageBox(f'Errore comando Configura IA:\n{traceback.format_exc()}')


class ConfiguraIACommandCreatedHandler(adsk.core.CommandCreatedEventHandler):
    """Handler creazione dialog"""
    
    def __init__(self, config_manager, config):
        super().__init__()
        self.config_manager = config_manager
        self.config = config
    
    def notify(self, args):
        try:
            cmd = args.command
            inputs = cmd.commandInputs
            
            # ===== CHECK FIRST RUN =====
            is_first_run = self.config_manager.is_first_run()
            
            # ===== MESSAGGIO FIRST RUN =====
            if is_first_run:
                inputs.addTextBoxCommandInput(
                    'first_run_msg',
                    '',
                    'üéâ <b>BENVENUTO IN FURNITUREAI PROFESSIONAL!</b>\n\n'
                    'Questa √® la prima volta che avvii l\'addon.\n\n'
                    '<b>‚öôÔ∏è Configurazione IA (Opzionale):</b>\n'
                    '‚Ä¢ <b>Lascia tutto DISABILITATO</b> per lavorare offline senza IA\n'
                    '  ‚Üí Zero costi, massima privacy\n'
                    '  ‚Üí Tutti i comandi standard funzionano\n\n'
                    '‚Ä¢ <b>Oppure configura un provider</b> per abilitare funzioni IA:\n'
                    '  ‚Üí Genera mobili da descrizione testuale\n'
                    '  ‚Üí Layout automatico cucine da pianta\n'
                    '  ‚Üí Analisi immagini mobili\n\n'
                    '<i>üí° Puoi sempre tornare qui da: Impostazioni ‚Üí Configura IA</i>',
                    9,
                    True
                )
            
            # ===== TOGGLE GLOBALE IA =====
            group_global = inputs.addGroupCommandInput('group_global', 'üîå Funzionalit√† IA')
            group_global.isExpanded = True
            group_global_inputs = group_global.children
            
            # Determina valore toggle
            if is_first_run:
                ai_enabled = False  # Default OFF per first run
            else:
                ai_enabled = self.config.get('ai_features_enabled', False) if self.config else False
            
            toggle_ai = group_global_inputs.addBoolValueInput(
                'ai_features_enabled',
                'Abilita Funzionalit√† IA',
                True,
                '',
                ai_enabled
            )
            
            group_global_inputs.addTextBoxCommandInput(
                'toggle_help',
                '',
                '<b>üí° Come Funziona:</b>\n\n'
                '‚úó <b>DISABILITATO (Raccomandato per iniziare):</b>\n'
                '   ‚Ä¢ Lavoro completamente offline\n'
                '   ‚Ä¢ Nessun costo, massima privacy\n'
                '   ‚Ä¢ Comandi IA non disponibili\n'
                '   ‚Ä¢ Tutti gli altri comandi funzionano normalmente\n\n'
                '‚úì <b>ABILITATO:</b>\n'
                '   ‚Ä¢ Comandi IA disponibili (se provider configurato sotto)\n'
                '   ‚Ä¢ Genera mobili da testo: "Credenza 180cm rovere"\n'
                '   ‚Ä¢ Genera layout da pianta 2D\n'
                '   ‚Ä¢ Analisi immagini mobili\n\n'
                '<i>‚ö†Ô∏è Riavvia addon dopo modifiche per applicare cambiamenti.</i>',
                10,
                True
            )
            
            # ===== INFO GENERALE =====
            inputs.addTextBoxCommandInput(
                'help_text',
                '',
                '<b>üìã Provider IA Disponibili:</b>\n\n'
                'FurnitureAI supporta provider multipli con fallback automatico:\n\n'
                '‚Ä¢ <b>üíª PC Locale/LAN</b>\n'
                '  Esegui IA su questa macchina o su PC in rete locale\n'
                '  ‚Üí Privacy massima, zero costi, funziona offline\n\n'
                '‚Ä¢ <b>üåê Internet (Remoto)</b>\n'
                '  Accedi al tuo server NPU da ovunque via Internet\n'
                '  ‚Üí Usa VPN/Cloudflare per accesso sicuro\n\n'
                '‚Ä¢ <b>‚òÅÔ∏è Cloud Esterno</b>\n'
                '  OpenAI, Anthropic - Servizi professionali\n'
                '  ‚Üí Qualit√† massima, costi per utilizzo\n\n'
                '<i>Configura almeno un provider per usare funzioni IA</i>',
                9,
                True
            )
            
            # ===== TAB 1: PC LOCALE / LAN =====
            tab_local = inputs.addTabCommandInput('tab_local', 'üíª PC Locale/LAN')
            tab_local_inputs = tab_local.children
            
            tab_local_inputs.addTextBoxCommandInput(
                'local_info',
                '',
                '<b>üíª Server IA su PC Locale o Rete Locale (LAN)</b>\n\n'
                '<b>Esegui IA su:</b>\n'
                '‚Ä¢ Questa stessa macchina (localhost)\n'
                '‚Ä¢ Altro PC in casa/ufficio (rete locale)\n\n'
                '<b>Vantaggi:</b>\n'
                '‚úì Privacy totale (dati non escono dal tuo PC/rete)\n'
                '‚úì Zero costi API\n'
                '‚úì Funziona senza Internet\n'
                '‚úì Velocit√† dipende dalla tua GPU/NPU\n\n'
                '<i>Richiede: LM Studio o Ollama installato</i>',
                7,
                True
            )
            
            # LM Studio
            group_lmstudio = tab_local_inputs.addGroupCommandInput('group_lmstudio', 'LM Studio')
            group_lmstudio_inputs = group_lmstudio.children
            
            lmstudio_enabled_default = False
            lmstudio_url_default = "http://localhost:1234/v1"
            lmstudio_model_default = "llama-3.1-8b-instruct"
            
            if not is_first_run and self.config:
                lmstudio_enabled_default = self.config.get('local_lan', {}).get('lmstudio', {}).get('enabled', False)
                lmstudio_url_default = self.config.get('local_lan', {}).get('lmstudio', {}).get('base_url', lmstudio_url_default)
                lmstudio_model_default = self.config.get('local_lan', {}).get('lmstudio', {}).get('model_text', lmstudio_model_default)
            
            group_lmstudio_inputs.addBoolValueInput(
                'lmstudio_enabled',
                'Abilita LM Studio',
                True,
                '',
                lmstudio_enabled_default
            )
            
            group_lmstudio_inputs.addStringValueInput(
                'lmstudio_url',
                'URL Server',
                lmstudio_url_default
            )
            
            group_lmstudio_inputs.addStringValueInput(
                'lmstudio_model',
                'Modello',
                lmstudio_model_default
            )
            
            group_lmstudio_inputs.addTextBoxCommandInput(
                'lmstudio_help',
                '',
                '<b>üìç Esempi URL:</b>\n'
                '‚Ä¢ <b>Stesso PC:</b> http://localhost:1234/v1 (default)\n'
                '‚Ä¢ <b>Altro PC in LAN:</b> http://192.168.1.100:1234/v1\n\n'
                '<b>Modelli consigliati:</b>\n'
                '‚Ä¢ llama-3.1-8b-instruct (veloce, 8GB VRAM)\n'
                '‚Ä¢ llama-3.1-70b-instruct (qualit√† massima, 40GB VRAM)\n\n'
                '<i>Download LM Studio: https://lmstudio.ai</i>',
                5,
                True
            )
            
            # Ollama
            group_ollama = tab_local_inputs.addGroupCommandInput('group_ollama', 'Ollama')
            group_ollama_inputs = group_ollama.children
            
            ollama_enabled_default = False
            ollama_url_default = "http://localhost:11434"
            ollama_model_text_default = "llama3.1:8b"
            ollama_model_vision_default = "llava:13b"
            
            if not is_first_run and self.config:
                ollama_enabled_default = self.config.get('local_lan', {}).get('ollama', {}).get('enabled', False)
                ollama_url_default = self.config.get('local_lan', {}).get('ollama', {}).get('base_url', ollama_url_default)
                ollama_model_text_default = self.config.get('local_lan', {}).get('ollama', {}).get('model_text', ollama_model_text_default)
                ollama_model_vision_default = self.config.get('local_lan', {}).get('ollama', {}).get('model_vision', ollama_model_vision_default)
            
            group_ollama_inputs.addBoolValueInput(
                'ollama_enabled',
                'Abilita Ollama',
                True,
                '',
                ollama_enabled_default
            )
            
            group_ollama_inputs.addStringValueInput(
                'ollama_url',
                'URL Server',
                ollama_url_default
            )
            
            group_ollama_inputs.addStringValueInput(
                'ollama_model_text',
                'Modello Testo',
                ollama_model_text_default
            )
            
            group_ollama_inputs.addStringValueInput(
                'ollama_model_vision',
                'Modello Vision (Analisi Immagini)',
                ollama_model_vision_default
            )
            
            group_ollama_inputs.addTextBoxCommandInput(
                'ollama_help',
                '',
                '<b>üìç Esempi URL:</b>\n'
                '‚Ä¢ <b>Stesso PC:</b> http://localhost:11434 (default)\n'
                '‚Ä¢ <b>Altro PC in LAN:</b> http://192.168.1.100:11434\n\n'
                '<b>Modelli consigliati:</b>\n'
                '‚Ä¢ Testo: llama3.1:8b (veloce, 8GB)\n'
                '‚Ä¢ Vision: llava:13b (analisi immagini, 13GB)\n\n'
                '<b>Setup rapido:</b>\n'
                '1. Download: https://ollama.com\n'
                '2. ollama pull llama3.1:8b\n'
                '3. ollama serve',
                7,
                True
            )
            
            # Test Locale
            tab_local_inputs.addBoolValueInput('test_local', 'üîç Test Connessione PC Locale', False, '', False)
            
            # ===== TAB 2: CLOUD GRATIS (NUOVO) =====
            tab_free = inputs.addTabCommandInput('tab_free', 'üÜì Cloud Gratis')
            tab_free_inputs = tab_free.children
            
            tab_free_inputs.addTextBoxCommandInput(
                'free_info',
                '',
                '<b>üÜì Provider Cloud GRATUITI</b>\n\n'
                '<b>üí° Perfetto per iniziare senza costi!</b>\n\n'
                '<b>Vantaggi:</b>\n'
                '‚úì 100% Gratis (limiti giornalieri generosi)\n'
                '‚úì Nessuna carta di credito richiesta\n'
                '‚úì Qualit√† eccellente\n'
                '‚úì Setup in 2 minuti\n\n'
                '<b>Provider disponibili:</b>\n'
                '‚Ä¢ <b>‚ö° Groq:</b> Chat velocissimo (14,400 req/giorno)\n'
                '‚Ä¢ <b>ü§ó HuggingFace:</b> Vision + Image Gen + Chat\n\n'
                '<i>Consigliato per provare le funzionalit√† IA gratuitamente</i>',
                9,
                True
            )
            
            # Groq
            group_groq = tab_free_inputs.addGroupCommandInput('group_groq', '‚ö° Groq (Chat Veloce)')
            group_groq_inputs = group_groq.children
            
            groq_enabled_default = False
            groq_key_default = ""
            groq_model_default = "llama-3.3-70b-versatile"
            
            if not is_first_run and self.config:
                groq_enabled_default = self.config.get('cloud', {}).get('groq', {}).get('enabled', False)
                groq_key_default = self.config.get('cloud', {}).get('groq', {}).get('api_key', "")
                groq_model_default = self.config.get('cloud', {}).get('groq', {}).get('model_text', groq_model_default)
            
            group_groq_inputs.addBoolValueInput(
                'groq_enabled',
                'Abilita Groq',
                True,
                '',
                groq_enabled_default
            )
            
            groq_key_input = group_groq_inputs.addStringValueInput(
                'groq_key',
                'API Key',
                groq_key_default
            )
            
            group_groq_inputs.addStringValueInput(
                'groq_model',
                'Modello',
                groq_model_default
            )
            
            group_groq_inputs.addTextBoxCommandInput(
                'groq_help',
                '',
                '<b>üîë Come ottenere API Key GRATIS:</b>\n'
                '1. Vai su https://console.groq.com\n'
                '2. Crea account (no carta credito)\n'
                '3. API Keys ‚Üí Create API Key\n'
                '4. Copia chiave e incolla qui\n\n'
                '<b>‚ö° Caratteristiche:</b>\n'
                '‚Ä¢ 14,400 richieste/giorno GRATIS\n'
                '‚Ä¢ Velocit√†: ~500 token/secondo (incredibile!)\n'
                '‚Ä¢ Modelli: Llama 3.3 70B, Mixtral, etc.\n'
                '‚Ä¢ Qualit√† eccellente\n\n'
                '<b>üí∞ Costi:</b> $0 (completamente gratis)\n\n'
                '<b>Modelli disponibili:</b>\n'
                '‚Ä¢ llama-3.3-70b-versatile (consigliato)\n'
                '‚Ä¢ llama-3.1-70b-versatile\n'
                '‚Ä¢ mixtral-8x7b-32768',
                11,
                True
            )
            
            # HuggingFace
            group_hf = tab_free_inputs.addGroupCommandInput('group_hf', 'ü§ó HuggingFace (Vision + Image Gen)')
            group_hf_inputs = group_hf.children
            
            hf_enabled_default = False
            hf_token_default = ""
            hf_model_text_default = "meta-llama/Llama-3.1-8B-Instruct"
            hf_model_vision_default = "Salesforce/blip-image-captioning-large"
            hf_model_image_default = "stabilityai/stable-diffusion-xl-base-1.0"
            
            if not is_first_run and self.config:
                hf_config = self.config.get('cloud', {}).get('huggingface', {})
                hf_enabled_default = hf_config.get('enabled', False)
                hf_token_default = hf_config.get('token', "")
                hf_models = hf_config.get('models', {})
                hf_model_text_default = hf_models.get('text', hf_model_text_default)
                hf_model_vision_default = hf_models.get('vision', hf_model_vision_default)
                hf_model_image_default = hf_models.get('image_gen', hf_model_image_default)
            
            group_hf_inputs.addBoolValueInput(
                'hf_enabled',
                'Abilita HuggingFace',
                True,
                '',
                hf_enabled_default
            )
            
            hf_token_input = group_hf_inputs.addStringValueInput(
                'hf_token',
                'Access Token',
                hf_token_default
            )
            
            group_hf_inputs.addStringValueInput(
                'hf_model_text',
                'Modello Text',
                hf_model_text_default
            )
            
            group_hf_inputs.addStringValueInput(
                'hf_model_vision',
                'Modello Vision',
                hf_model_vision_default
            )
            
            group_hf_inputs.addStringValueInput(
                'hf_model_image',
                'Modello Image Gen',
                hf_model_image_default
            )
            
            group_hf_inputs.addTextBoxCommandInput(
                'hf_help',
                '',
                '<b>üîë Come ottenere Access Token GRATIS:</b>\n'
                '1. Vai su https://huggingface.co/settings/tokens\n'
                '2. Crea account (no carta credito)\n'
                '3. New token ‚Üí Read access\n'
                '4. Copia token e incolla qui\n\n'
                '<b>üé® Funzionalit√†:</b>\n'
                '‚Ä¢ Chat testuale (Llama, Mistral, etc.)\n'
                '‚Ä¢ Vision: Analisi immagini mobili\n'
                '‚Ä¢ Image Gen: Genera concept da testo\n'
                '‚Ä¢ Migliaia di modelli disponibili\n\n'
                '<b>üí∞ Costi:</b> $0 (completamente gratis)\n'
                '  ‚Ä¢ Inference API gratis (con rate limit)\n'
                '  ‚Ä¢ Modelli open source illimitati\n\n'
                '<b>üìå Nota:</b> Primi utilizzi possono richiedere 20s\n'
                '  (warm-up modello), poi istantaneo',
                12,
                True
            )
            
            # Test Free Cloud
            tab_free_inputs.addBoolValueInput('test_free', 'üîç Test Connessione Provider Gratis', False, '', False)
            
            # ===== TAB 3: INTERNET (REMOTO) =====
            tab_remote = inputs.addTabCommandInput('tab_remote', 'üåê Internet (Remoto)')
            tab_remote_inputs = tab_remote.children
            
            tab_remote_inputs.addTextBoxCommandInput(
                'remote_info',
                '',
                '<b>üåê Server IA Accessibile via Internet</b>\n\n'
                '<b>Quando usare:</b>\n'
                '‚Ä¢ Hai server NPU a casa ma lavori da FUORI (altro ufficio, viaggio)\n'
                '‚Ä¢ Vuoi accesso da ovunque mantenendo il tuo hardware\n\n'
                '<b>Metodi accesso sicuro:</b>\n'
                '‚úì Cloudflare Tunnel (HTTPS gratis)\n'
                '‚úì Tailscale VPN (rete privata virtuale)\n'
                '‚úì WireGuard/OpenVPN\n\n'
                '<b>‚ö†Ô∏è NON esporre MAI direttamente a Internet senza protezione!</b>\n\n'
                '<i>Setup avanzato: consulta docs/SERVER_NPU_SETUP.md</i>',
                8,
                True
            )
            
            group_custom = tab_remote_inputs.addGroupCommandInput('group_custom', 'Server Custom HTTPS/VPN')
            group_custom_inputs = group_custom.children
            
            custom_enabled_default = False
            custom_url_default = ""
            custom_key_default = ""
            
            if not is_first_run and self.config:
                custom_enabled_default = self.config.get('remote_wan', {}).get('custom_server', {}).get('enabled', False)
                custom_url_default = self.config.get('remote_wan', {}).get('custom_server', {}).get('base_url', "")
                custom_key_default = self.config.get('remote_wan', {}).get('custom_server', {}).get('api_key', "")
            
            group_custom_inputs.addBoolValueInput(
                'custom_enabled',
                'Abilita Server Remoto',
                True,
                '',
                custom_enabled_default
            )
            
            group_custom_inputs.addStringValueInput(
                'custom_url',
                'URL Server (HTTPS/VPN)',
                custom_url_default
            )
            
            custom_key_input = group_custom_inputs.addStringValueInput(
                'custom_key',
                'API Key (opzionale)',
                custom_key_default
            )
            
            group_custom_inputs.addTextBoxCommandInput(
                'custom_help',
                '',
                '<b>üìç Esempi URL:</b>\n'
                '‚Ä¢ <b>Cloudflare Tunnel:</b> https://xxxx.trycloudflare.com\n'
                '‚Ä¢ <b>Tailscale VPN:</b> http://100.64.x.x:11434\n'
                '‚Ä¢ <b>Dominio custom:</b> https://ai.tuodominio.com\n\n'
                '<b>Setup Cloudflare Tunnel (consigliato):</b>\n'
                '1. cloudflared tunnel --url http://localhost:11434\n'
                '2. Usa URL generato (es: https://xxxx.trycloudflare.com)\n\n'
                '<i>HTTPS obbligatorio per sicurezza</i>',
                6,
                True
            )
            
            tab_remote_inputs.addBoolValueInput('test_remote', 'üîç Test Connessione Internet', False, '', False)
            
            # ===== TAB 4: CLOUD PREMIUM =====
            tab_cloud = inputs.addTabCommandInput('tab_cloud', '‚òÅÔ∏è Cloud Premium')
            tab_cloud_inputs = tab_cloud.children
            
            tab_cloud_inputs.addTextBoxCommandInput(
                'cloud_info',
                '',
                '<b>‚òÅÔ∏è Provider Cloud Professionali</b>\n\n'
                '<b>Quando usare:</b>\n'
                '‚Ä¢ Non hai GPU/NPU per server locale\n'
                '‚Ä¢ Progetti professionali che richiedono qualit√† massima\n'
                '‚Ä¢ Non vuoi gestire infrastruttura server\n\n'
                '<b>Pro:</b>\n'
                '‚úì Qualit√† top (GPT-4o, Claude 3.5 Sonnet)\n'
                '‚úì Sempre disponibile (99.9% uptime)\n'
                '‚úì Zero manutenzione\n\n'
                '<b>Contro:</b>\n'
                '‚úó Costi per utilizzo (API key richiesta)\n'
                '‚úó Dati progetti inviati a server esterni\n'
                '‚úó Richiede Internet\n\n'
                '<i>Consigliato per progetti professionali critici</i>',
                9,
                True
            )
            
            # OpenAI
            group_openai = tab_cloud_inputs.addGroupCommandInput('group_openai', 'OpenAI (GPT-4o)')
            group_openai_inputs = group_openai.children
            
            openai_enabled_default = False
            openai_key_default = ""
            
            if not is_first_run and self.config:
                openai_enabled_default = self.config.get('cloud', {}).get('openai', {}).get('enabled', False)
                openai_key_default = self.config.get('cloud', {}).get('openai', {}).get('api_key', "")
            
            group_openai_inputs.addBoolValueInput(
                'openai_enabled',
                'Abilita OpenAI',
                True,
                '',
                openai_enabled_default
            )
            
            openai_key_input = group_openai_inputs.addStringValueInput(
                'openai_key',
                'API Key',
                openai_key_default
            )
            
            group_openai_inputs.addTextBoxCommandInput(
                'openai_help',
                '',
                '<b>üîë Come ottenere API Key:</b>\n'
                '1. Vai su https://platform.openai.com/api-keys\n'
                '2. Crea nuovo account (se necessario)\n'
                '3. Click "Create new secret key"\n'
                '4. Copia chiave e incolla qui\n\n'
                '<b>Modelli usati automaticamente:</b>\n'
                '‚Ä¢ gpt-4o-mini (testo, veloce, economico)\n'
                '‚Ä¢ gpt-4o (vision, qualit√† massima)\n'
                '‚Ä¢ dall-e-3 (generazione immagini)\n\n'
                '<b>üí∞ Costi stimati:</b>\n'
                '‚Ä¢ ~$0.10-0.20 per richiesta media\n'
                '‚Ä¢ Credito iniziale: $5 gratis (trial)',
                8,
                True
            )
            
            # Anthropic
            group_anthropic = tab_cloud_inputs.addGroupCommandInput('group_anthropic', 'Anthropic (Claude 3.5)')
            group_anthropic_inputs = group_anthropic.children
            
            anthropic_enabled_default = False
            anthropic_key_default = ""
            
            if not is_first_run and self.config:
                anthropic_enabled_default = self.config.get('cloud', {}).get('anthropic', {}).get('enabled', False)
                anthropic_key_default = self.config.get('cloud', {}).get('anthropic', {}).get('api_key', "")
            
            group_anthropic_inputs.addBoolValueInput(
                'anthropic_enabled',
                'Abilita Anthropic',
                True,
                '',
                anthropic_enabled_default
            )
            
            anthropic_key_input = group_anthropic_inputs.addStringValueInput(
                'anthropic_key',
                'API Key',
                anthropic_key_default
            )
            
            group_anthropic_inputs.addTextBoxCommandInput(
                'anthropic_help',
                '',
                '<b>üîë Come ottenere API Key:</b>\n'
                '1. Vai su https://console.anthropic.com/\n'
                '2. Crea account\n'
                '3. Settings ‚Üí API Keys ‚Üí Create Key\n'
                '4. Copia e incolla qui\n\n'
                '<b>Modello usato:</b>\n'
                '‚Ä¢ claude-3-5-sonnet-20241022\n'
                '‚Ä¢ Context window: 200K token (ottimo per progetti complessi)\n'
                '‚Ä¢ Eccellente per reasoning complesso\n\n'
                '<b>üí∞ Costi stimati:</b>\n'
                '‚Ä¢ ~$0.20-0.40 per richiesta media\n'
                '‚Ä¢ Credito iniziale: $5 gratis (trial)',
                8,
                True
            )
            
            tab_cloud_inputs.addBoolValueInput('test_cloud', 'üîç Test Connessione Cloud', False, '', False)
            
            # ===== STATUS CORRENTE (se non first run) =====
            if not is_first_run and self.config:
                group_status = inputs.addGroupCommandInput('group_status', 'üìä Status Configurazione Attuale')
                group_status.isExpanded = False
                group_status_inputs = group_status.children
                
                status_text = self._get_status_text()
                group_status_inputs.addTextBoxCommandInput('status_text', '', status_text, 6, True)
            
            # ===== HANDLER EXECUTE =====
            on_execute = ConfiguraIAExecuteHandler(self.config_manager, self.config)
            cmd.execute.add(on_execute)
            
            # ===== HANDLER INPUT CHANGED (per test connessione) =====
            on_input_changed = ConfiguraIAInputChangedHandler(self.config_manager)
            cmd.inputChanged.add(on_input_changed)
            
        except:
            adsk.core.Application.get().userInterface.messageBox(
                f'Errore creazione dialog:\n{traceback.format_exc()}'
            )
    
    def _get_status_text(self):
        """Genera testo status configurazione corrente"""
        if not self.config:
            return "Nessuna configurazione trovata"
        
        status = "CONFIGURAZIONE ATTUALE:\n\n"
        
        # Toggle globale
        ai_enabled = self.config.get('ai_features_enabled', False)
        status += f"Toggle IA: {'‚úì ABILITATO' if ai_enabled else '‚úó DISABILITATO'}\n\n"
        
        # Provider configurati
        status += "PROVIDER CONFIGURATI:\n"
        
        # LM Studio
        if self.config.get('local_lan', {}).get('lmstudio', {}).get('enabled'):
            status += "  ‚úì LM Studio (PC Locale)\n"
        
        # Ollama
        if self.config.get('local_lan', {}).get('ollama', {}).get('enabled'):
            status += "  ‚úì Ollama (PC Locale)\n"
        
        # Groq
        if self.config.get('cloud', {}).get('groq', {}).get('enabled'):
            status += "  ‚úì Groq (Cloud Gratis)\n"
        
        # HuggingFace
        if self.config.get('cloud', {}).get('huggingface', {}).get('enabled'):
            status += "  ‚úì HuggingFace (Cloud Gratis)\n"
        
        # Server Remoto
        if self.config.get('remote_wan', {}).get('custom_server', {}).get('enabled'):
            status += "  ‚úì Server Remoto (Internet)\n"
        
        # OpenAI
        if self.config.get('cloud', {}).get('openai', {}).get('enabled'):
            status += "  ‚úì OpenAI (Cloud)\n"
        
        # Anthropic
        if self.config.get('cloud', {}).get('anthropic', {}).get('enabled'):
            status += "  ‚úì Anthropic (Cloud)\n"
        
        if not any([
            self.config.get('local_lan', {}).get('lmstudio', {}).get('enabled'),
            self.config.get('local_lan', {}).get('ollama', {}).get('enabled'),
            self.config.get('cloud', {}).get('groq', {}).get('enabled'),
            self.config.get('cloud', {}).get('huggingface', {}).get('enabled'),
            self.config.get('remote_wan', {}).get('custom_server', {}).get('enabled'),
            self.config.get('cloud', {}).get('openai', {}).get('enabled'),
            self.config.get('cloud', {}).get('anthropic', {}).get('enabled')
        ]):
            status += "  Nessun provider configurato\n"
        
        return status


class ConfiguraIAInputChangedHandler(adsk.core.InputChangedEventHandler):
    """Handler cambio input (test connessione)"""
    
    def __init__(self, config_manager):
        super().__init__()
        self.config_manager = config_manager
    
    def notify(self, args):
        try:
            changed_input = args.input
            
            if changed_input.id == 'test_local':
                self._test_local(args.inputs)
            elif changed_input.id == 'test_free':
                self._test_free(args.inputs)
            elif changed_input.id == 'test_remote':
                self._test_remote(args.inputs)
            elif changed_input.id == 'test_cloud':
                self._test_cloud(args.inputs)
        except:
            pass
    
    def _test_local(self, inputs):
        """Test server locale"""
        app = adsk.core.Application.get()
        
        result = "üîç TEST SERVER PC LOCALE\n\n"
        
        # Test LM Studio
        if inputs.itemById('lmstudio_enabled').value:
            url = inputs.itemById('lmstudio_url').value
            result += f"LM Studio ({url}):\n"
            try:
                import requests
                response = requests.get(f"{url}/models", timeout=3)
                if response.status_code == 200:
                    result += "  ‚úì Connessione OK\n"
                else:
                    result += f"  ‚úó Errore HTTP {response.status_code}\n"
            except Exception as e:
                result += f"  ‚úó Non raggiungibile\n  Verifica che LM Studio sia avviato\n"
        
        # Test Ollama
        if inputs.itemById('ollama_enabled').value:
            url = inputs.itemById('ollama_url').value
            result += f"\nOllama ({url}):\n"
            try:
                import requests
                response = requests.get(f"{url}/api/tags", timeout=3)
                if response.status_code == 200:
                    result += "  ‚úì Connessione OK\n"
                    data = response.json()
                    if 'models' in data:
                        result += f"  Modelli disponibili: {len(data['models'])}\n"
                else:
                    result += f"  ‚úó Errore HTTP {response.status_code}\n"
            except Exception as e:
                result += f"  ‚úó Non raggiungibile\n  Verifica che Ollama sia avviato: ollama serve\n"
        
        if not inputs.itemById('lmstudio_enabled').value and not inputs.itemById('ollama_enabled').value:
            result += "Nessun server locale abilitato"
        
        app.userInterface.messageBox(result, 'Test Server Locale')
    
    def _test_free(self, inputs):
        """Test provider gratuiti (Groq, HuggingFace)"""
        app = adsk.core.Application.get()
        
        result = "üîç TEST PROVIDER GRATUITI\n\n"
        
        # Test Groq
        if inputs.itemById('groq_enabled').value:
            api_key = inputs.itemById('groq_key').value
            if api_key:
                result += "‚ö° Groq:\n"
                try:
                    import requests
                    headers = {
                        'Authorization': f'Bearer {api_key}',
                        'Content-Type': 'application/json'
                    }
                    payload = {
                        "model": inputs.itemById('groq_model').value,
                        "messages": [{"role": "user", "content": "Test"}],
                        "max_tokens": 10
                    }
                    response = requests.post(
                        'https://api.groq.com/openai/v1/chat/completions',
                        headers=headers,
                        json=payload,
                        timeout=10
                    )
                    if response.status_code == 200:
                        result += "  ‚úì API Key valida\n  ‚úì Connessione OK\n  ‚úì Velocit√†: Incredibile!\n"
                    elif response.status_code == 401:
                        result += "  ‚úó API Key non valida\n  Verifica chiave copiata correttamente\n"
                    else:
                        result += f"  ‚úó Errore: {response.status_code}\n"
                except Exception as e:
                    result += f"  ‚úó Errore connessione\n"
            else:
                result += "‚ö° Groq: API Key non inserita\n"
        
        # Test HuggingFace
        if inputs.itemById('hf_enabled').value:
            token = inputs.itemById('hf_token').value
            if token:
                result += "\nü§ó HuggingFace:\n"
                try:
                    import requests
                    headers = {'Authorization': f'Bearer {token}'}
                    
                    # Test con modello leggero
                    response = requests.post(
                        'https://api-inference.huggingface.co/models/gpt2',
                        headers=headers,
                        json={"inputs": "Test"},
                        timeout=10
                    )
                    if response.status_code == 200:
                        result += "  ‚úì Token valido\n  ‚úì Connessione OK\n  ‚úì Accesso a migliaia di modelli!\n"
                    elif response.status_code == 401:
                        result += "  ‚úó Token non valido\n  Verifica token copiato correttamente\n"
                    else:
                        result += f"  ‚úó Errore: {response.status_code}\n"
                except Exception as e:
                    result += f"  ‚úó Errore connessione\n"
            else:
                result += "\nü§ó HuggingFace: Token non inserito\n"
        
        if not inputs.itemById('groq_enabled').value and not inputs.itemById('hf_enabled').value:
            result += "Nessun provider gratuito abilitato"
        
        app.userInterface.messageBox(result, 'Test Provider Gratuiti')
    
    def _test_remote(self, inputs):
        """Test server remoto"""
        app = adsk.core.Application.get()
        
        result = "üîç TEST SERVER REMOTO (Internet)\n\n"
        
        if inputs.itemById('custom_enabled').value:
            url = inputs.itemById('custom_url').value
            if url:
                result += f"Server ({url}):\n"
                try:
                    import requests
                    response = requests.get(f"{url}/health", timeout=5)
                    if response.status_code == 200:
                        result += "  ‚úì Server raggiungibile\n"
                    else:
                        result += f"  ‚úó Errore HTTP {response.status_code}\n"
                except Exception as e:
                    result += f"  ‚úó Non raggiungibile\n  Verifica:\n  ‚Ä¢ URL corretto\n  ‚Ä¢ Tunnel/VPN attivo\n  ‚Ä¢ Firewall\n"
            else:
                result += "URL non configurato"
        else:
            result += "Server remoto non abilitato"
        
        app.userInterface.messageBox(result, 'Test Server Remoto')
    
    def _test_cloud(self, inputs):
        """Test provider cloud"""
        app = adsk.core.Application.get()
        
        result = "üîç TEST PROVIDER CLOUD\n\n"
        
        # Test OpenAI
        if inputs.itemById('openai_enabled').value:
            api_key = inputs.itemById('openai_key').value
            if api_key:
                result += "OpenAI:\n"
                try:
                    import requests
                    headers = {'Authorization': f'Bearer {api_key}'}
                    response = requests.get('https://api.openai.com/v1/models', headers=headers, timeout=5)
                    if response.status_code == 200:
                        result += "  ‚úì API Key valida\n  ‚úì Connessione OK\n"
                    elif response.status_code == 401:
                        result += "  ‚úó API Key non valida\n  Verifica chiave copiata correttamente\n"
                    else:
                        result += f"  ‚úó Errore: {response.status_code}\n"
                except Exception as e:
                    result += f"  ‚úó Errore connessione Internet\n"
            else:
                result += "OpenAI: API Key non inserita\n"
        
        # Test Anthropic
        if inputs.itemById('anthropic_enabled').value:
            api_key = inputs.itemById('anthropic_key').value
            if api_key:
                result += "\nAnthropic:\n"
                try:
                    import requests
                    headers = {
                        'x-api-key': api_key,
                        'anthropic-version': '2023-06-01',
                        'content-type': 'application/json'
                    }
                    payload = {
                        "model": "claude-3-5-sonnet-20241022",
                        "max_tokens": 10,
                        "messages": [{"role": "user", "content": "test"}]
                    }
                    response = requests.post('https://api.anthropic.com/v1/messages', 
                                            headers=headers, json=payload, timeout=5)
                    if response.status_code == 200:
                        result += "  ‚úì API Key valida\n  ‚úì Connessione OK\n"
                    elif response.status_code == 401:
                        result += "  ‚úó API Key non valida\n  Verifica chiave copiata correttamente\n"
                    else:
                        result += f"  ‚úó Errore: {response.status_code}\n"
                except Exception as e:
                    result += f"  ‚úó Errore connessione Internet\n"
            else:
                result += "\nAnthropic: API Key non inserita\n"
        
        if not inputs.itemById('openai_enabled').value and not inputs.itemById('anthropic_enabled').value:
            result += "Nessun provider cloud abilitato"
        
        app.userInterface.messageBox(result, 'Test Provider Cloud')


class ConfiguraIAExecuteHandler(adsk.core.CommandEventHandler):
    """Handler execute (salvataggio)"""
    
    def __init__(self, config_manager, config):
        super().__init__()
        self.config_manager = config_manager
        self.config = config
    
    def notify(self, args):
        try:
            app = adsk.core.Application.get()
            inputs = args.command.commandInputs
            
            # ===== CHECK FIRST RUN =====
            is_first_run = self.config_manager.is_first_run()
            
            # ===== CREA CONFIG TEMPLATE SE NECESSARIO =====
            if is_first_run or self.config is None:
                self.config = {
                    "ai_features_enabled": False,
                    "cloud": {
                        "openai": {
                            "api_key": "",
                            "model_text": "gpt-4o-mini",
                            "model_vision": "gpt-4o",
                            "model_image": "dall-e-3",
                            "enabled": False
                        },
                        "anthropic": {
                            "api_key": "",
                            "model": "claude-3-5-sonnet-20241022",
                            "enabled": False
                        },
                        "groq": {
                            "api_key": "",
                            "base_url": "https://api.groq.com/openai/v1",
                            "model_text": "llama-3.3-70b-versatile",
                            "enabled": False,
                            "timeout": 30
                        },
                        "huggingface": {
                            "token": "",
                            "base_url": "https://api-inference.huggingface.co",
                            "models": {
                                "text": "meta-llama/Llama-3.1-8B-Instruct",
                                "vision": "Salesforce/blip-image-captioning-large",
                                "image_gen": "stabilityai/stable-diffusion-xl-base-1.0"
                            },
                            "enabled": False,
                            "timeout": 60
                        }
                    },
                    "local_lan": {
                        "lmstudio": {
                            "base_url": "http://localhost:1234/v1",
                            "model_text": "llama-3.1-8b-instruct",
                            "enabled": False,
                            "timeout": 300
                        },
                        "ollama": {
                            "base_url": "http://localhost:11434",
                            "model_text": "llama3.1:8b",
                            "model_text_large": "llama3.1:70b",
                            "model_vision": "llava:13b",
                            "enabled": False,
                            "timeout": 300
                        }
                    },
                    "remote_wan": {
                        "custom_server": {
                            "base_url": "",
                            "api_key": "",
                            "enabled": False,
                            "verify_ssl": True,
                            "timeout": 600
                        }
                    },
                    "preferences": {
                        "priority_order": ["local_lan", "remote_wan", "cloud"],
                        "auto_fallback": True,
                        "prefer_npu_server": True,
                        "cache_responses": True
                    }
                }
            
            # ===== SALVA VALORI DA DIALOG =====
            
            # Toggle globale
            self.config['ai_features_enabled'] = inputs.itemById('ai_features_enabled').value
            
            # LM Studio
            self.config['local_lan']['lmstudio']['enabled'] = inputs.itemById('lmstudio_enabled').value
            self.config['local_lan']['lmstudio']['base_url'] = inputs.itemById('lmstudio_url').value
            self.config['local_lan']['lmstudio']['model_text'] = inputs.itemById('lmstudio_model').value
            
            # Ollama
            self.config['local_lan']['ollama']['enabled'] = inputs.itemById('ollama_enabled').value
            self.config['local_lan']['ollama']['base_url'] = inputs.itemById('ollama_url').value
            self.config['local_lan']['ollama']['model_text'] = inputs.itemById('ollama_model_text').value
            self.config['local_lan']['ollama']['model_vision'] = inputs.itemById('ollama_model_vision').value
            
            # Groq
            self.config['cloud']['groq']['enabled'] = inputs.itemById('groq_enabled').value
            self.config['cloud']['groq']['api_key'] = inputs.itemById('groq_key').value
            self.config['cloud']['groq']['model_text'] = inputs.itemById('groq_model').value
            
            # HuggingFace
            self.config['cloud']['huggingface']['enabled'] = inputs.itemById('hf_enabled').value
            self.config['cloud']['huggingface']['token'] = inputs.itemById('hf_token').value
            self.config['cloud']['huggingface']['models']['text'] = inputs.itemById('hf_model_text').value
            self.config['cloud']['huggingface']['models']['vision'] = inputs.itemById('hf_model_vision').value
            self.config['cloud']['huggingface']['models']['image_gen'] = inputs.itemById('hf_model_image').value
            
            # Server Custom
            self.config['remote_wan']['custom_server']['enabled'] = inputs.itemById('custom_enabled').value
            self.config['remote_wan']['custom_server']['base_url'] = inputs.itemById('custom_url').value
            self.config['remote_wan']['custom_server']['api_key'] = inputs.itemById('custom_key').value
            
            # OpenAI
            self.config['cloud']['openai']['enabled'] = inputs.itemById('openai_enabled').value
            self.config['cloud']['openai']['api_key'] = inputs.itemById('openai_key').value
            
            # Anthropic
            self.config['cloud']['anthropic']['enabled'] = inputs.itemById('anthropic_enabled').value
            self.config['cloud']['anthropic']['api_key'] = inputs.itemById('anthropic_key').value
            
            # ===== SALVA FILE CONFIG =====
            self.config_manager.save_ai_config(self.config)
            
            app.log("‚úì Configurazione salvata")
            
            # ===== MESSAGGIO PERSONALIZZATO =====
            if is_first_run:
                if inputs.itemById('ai_features_enabled').value:
                    # Controlla se almeno un provider √® configurato
                    has_provider = (
                        inputs.itemById('lmstudio_enabled').value or
                        inputs.itemById('ollama_enabled').value or
                        (inputs.itemById('groq_enabled').value and inputs.itemById('groq_key').value) or
                        (inputs.itemById('hf_enabled').value and inputs.itemById('hf_token').value) or
                        inputs.itemById('custom_enabled').value or
                        (inputs.itemById('openai_enabled').value and inputs.itemById('openai_key').value) or
                        (inputs.itemById('anthropic_enabled').value and inputs.itemById('anthropic_key').value)
                    )
                    
                    if has_provider:
                        msg = (
                            "‚úì Configurazione salvata!\n\n"
                            "üéâ IA ABILITATA E CONFIGURATA\n\n"
                            "Riavvia addon per applicare:\n"
                            "1. Script e Add-In ‚Üí FurnitureAI ‚Üí Stop\n"
                            "2. Run\n\n"
                            "I comandi IA saranno disponibili! üöÄ"
                        )
                    else:
                        msg = (
                            "‚ö†Ô∏è Configurazione salvata\n\n"
                            "Toggle IA √® ON ma nessun provider configurato.\n\n"
                            "Per abilitare comandi IA:\n"
                            "1. Configura almeno un provider\n"
                            "2. Riavvia addon\n\n"
                            "Oppure disabilita toggle IA per lavorare offline."
                        )
                else:
                    msg = (
                        "‚úì Configurazione salvata!\n\n"
                        "‚úó IA DISABILITATA\n\n"
                        "Modalit√† OFFLINE attiva.\n"
                        "Puoi usare tutti i comandi standard senza IA.\n\n"
                        "Per abilitare IA in futuro:\n"
                        "Impostazioni ‚Üí Configura IA"
                    )
            else:
                # Modifica configurazione esistente
                toggle_status = "ON" if inputs.itemById('ai_features_enabled').value else "OFF"
                msg = (
                    f"‚úì Configurazione salvata!\n\n"
                    f"Toggle IA: {toggle_status}\n\n"
                    f"Riavvia addon per applicare:\n"
                    f"1. Stop\n"
                    f"2. Run"
                )
            
            app.userInterface.messageBox(msg, 'Configurazione Salvata')
            
        except Exception as e:
            adsk.core.Application.get().userInterface.messageBox(
                f'Errore salvataggio:\n{str(e)}\n\n{traceback.format_exc()}'
            )


def run(context):
    """Entry point comando"""
    try:
        cmd = ConfiguraIACommand()
        cmd.execute()
    except:
        app = adsk.core.Application.get()
        if app:
            app.userInterface.messageBox(f'Errore:\n{traceback.format_exc()}')
