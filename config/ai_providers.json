{
  "providers": {
    "openai": {
      "id": "openai",
      "name": "OpenAI",
      "type": "cloud",
      "description": "OpenAI GPT-4 and GPT-3.5 models",
      "endpoint": "https://api.openai.com/v1/chat/completions",
      "requires_api_key": true,
      "models": [
        {
          "id": "gpt-4",
          "name": "GPT-4",
          "context_window": 8192,
          "supports_vision": false
        },
        {
          "id": "gpt-4-vision-preview",
          "name": "GPT-4 Vision",
          "context_window": 128000,
          "supports_vision": true
        },
        {
          "id": "gpt-3.5-turbo",
          "name": "GPT-3.5 Turbo",
          "context_window": 16385,
          "supports_vision": false
        }
      ]
    },
    "anthropic": {
      "id": "anthropic",
      "name": "Anthropic Claude",
      "type": "cloud",
      "description": "Anthropic Claude AI models",
      "endpoint": "https://api.anthropic.com/v1/messages",
      "requires_api_key": true,
      "models": [
        {
          "id": "claude-3-opus-20240229",
          "name": "Claude 3 Opus",
          "context_window": 200000,
          "supports_vision": true
        },
        {
          "id": "claude-3-sonnet-20240229",
          "name": "Claude 3 Sonnet",
          "context_window": 200000,
          "supports_vision": true
        },
        {
          "id": "claude-3-haiku-20240307",
          "name": "Claude 3 Haiku",
          "context_window": 200000,
          "supports_vision": true
        }
      ]
    },
    "lmstudio": {
      "id": "lmstudio",
      "name": "LM Studio",
      "type": "local",
      "description": "LM Studio local inference server",
      "endpoint": "http://localhost:1234/v1/chat/completions",
      "requires_api_key": false,
      "models": [
        {
          "id": "llama-3.2-3b-instruct",
          "name": "Llama 3.2 3B Instruct",
          "context_window": 8192,
          "supports_vision": false
        },
        {
          "id": "llama-3.1-8b-instruct",
          "name": "Llama 3.1 8B Instruct",
          "context_window": 131072,
          "supports_vision": false
        },
        {
          "id": "mistral-7b-instruct",
          "name": "Mistral 7B Instruct",
          "context_window": 32768,
          "supports_vision": false
        }
      ]
    },
    "ollama": {
      "id": "ollama",
      "name": "Ollama",
      "type": "local",
      "description": "Ollama local LLM runtime",
      "endpoint": "http://localhost:11434/api/generate",
      "requires_api_key": false,
      "models": [
        {
          "id": "llama3.2:3b",
          "name": "Llama 3.2 3B",
          "context_window": 8192,
          "supports_vision": false
        },
        {
          "id": "llama3.1:8b",
          "name": "Llama 3.1 8B",
          "context_window": 131072,
          "supports_vision": false
        },
        {
          "id": "llava:7b",
          "name": "LLaVA 7B (Vision)",
          "context_window": 4096,
          "supports_vision": true
        },
        {
          "id": "mistral:7b",
          "name": "Mistral 7B",
          "context_window": 32768,
          "supports_vision": false
        }
      ]
    },
    "custom": {
      "id": "custom",
      "name": "Custom Remote Server",
      "type": "remote",
      "description": "Custom remote NPU server with OpenAI-compatible API",
      "endpoint": "http://localhost:8000/v1/chat/completions",
      "requires_api_key": false,
      "models": [
        {
          "id": "custom-model",
          "name": "Custom Model",
          "context_window": 8192,
          "supports_vision": false
        }
      ]
    }
  },
  "default_settings": {
    "temperature": 0.7,
    "max_tokens": 2048,
    "timeout": 30,
    "retry_attempts": 3,
    "retry_delay": 1
  }
}
